\documentclass[10pt,a4paper]{exam} % turn it into a class! 
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{fancyeq}
\usepackage{tikz}
%\usepackage{tikz-uml}
\usepackage{mathpartir}
\usetikzlibrary{matrix,decorations.pathmorphing,shapes,arrows,backgrounds,positioning}
\usepackage{graphicx,xcolor}
\usepackage{geometry}
\usepackage{everysel}
\usepackage[normalem]{ulem}
\usepackage{mdframed}

\tikzset{
  treenode/.style = {align=center, inner sep=0pt, text centered,
    font=\sffamily},
  arn_n/.style = {treenode, circle, black, font=\sffamily\bfseries, draw=black,
    fill=white, text width=1.5em},% arbre rouge noir, noeud noir
  arn_r/.style = {treenode, circle, red, draw=red, 
    text width=1.5em, very thick},% arbre rouge noir, noeud rouge
  arn_x/.style = {treenode, rectangle, draw=black,
    minimum width=0.5em, minimum height=0.5em}% arbre rouge noir, nil
}

\usepackage[sc]{mathpazo}
\linespread{1.05}         % Palatino needs more leading (space between lines)
\usepackage[T1]{fontenc}

% some format settings
% for hard-bound final submission, use:
%\setlength{\oddsidemargin}{4.6mm}     % 30 mm left margin - 1 in
% for soft-bound version and techreport, use instead:

\setlength{\oddsidemargin}{-0.4mm}    % 25 mm left margin - 1 in
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{-5.4mm}        % 20 mm top margin - 1 in
\setlength{\textwidth}{160mm}         % 20/25 mm right margin
\setlength{\textheight}{237mm}        % 20 mm bottom margin
\setlength{\headheight}{5mm}
\setlength{\headsep}{5mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\renewcommand\baselinestretch{1.2} % thesis format (not needed for techreport)
% don't let large figures hijack entire pages
\renewcommand\topfraction{.9}
\renewcommand\textfraction{.1}
\renewcommand\floatpagefraction{.8}

\pagestyle{headandfoot}
%\pointsinrightmargin
%\pointname{ marks}
%\marginpointname{ marks}

\marksnotpoints 

\definecolor{campurple}{HTML}{862D91} 
\definecolor{campurpledark}{HTML}{2A185C}

\hypersetup{  
  urlcolor=campurple,
  linkcolor=campurple,
  colorlinks=true  
}

\titlelabel{\llap{\thetitle\quad}}

\newcommand {\lbrac} {\makebox[0pt]{[\kern-1ex[}}
\newcommand {\rbrac} {\makebox[0pt]{]\kern-1ex]}}
\newcommand{\denote}[1]{\lbrac~#1~\rbrac}


\def\mystrut(#1,#2){\vrule height #1pt depth #2pt width 0pt} 

\titlespacing*{\section}{0pt}{0pt}{0pt}


\begin{document}

\newcommand{\course}{Compiler Construction}
\newcommand{\week}{I}
%\newcommand{\topics}{Data, Subtyping \& Objects, Semantic Equivalence, and Concurrency}

\everymath{\color{campurpledark}}
\everydisplay{\color{campurpledark}}

%\vspace{15pt}

%\begin{center}
%\emph{Complete SECTION 1 and ONE other section.}
%\end{center}

%\begin{center}
%\emph{Answer SECTION 1 and TWO other sections.}
%\end{center}

\marksnotpoints
\pointsdroppedatright
\marksnotpoints
\marginpointname{ \points}

\begin{center}
\LARGE {\textbf{\color{campurpledark} \course} }\\[-0.2cm]
\Large \color{campurpledark} Supervision \week: The Spineless Tagless G-Machine Awakens\\
\end{center}

{\color{campurple}\hrule}

\newcommand{\metavar}[1]{{\color{campurple}#1}}

\vspace{0.5cm}

\newcommand{\terminal}[1]{\texttt{\color{campurple}#1}}
\newcommand{\bl}[1]{{\color{black}#1}}

%\section*{Introduction}

\begin{center}
\parbox[c]{340pt}{
%A long time ago in a galaxy far, far away... \\

In {Semantics of Programming Languages}, you have learned how to attach formal, operational semantics to the grammars of programming languages. In {Compiler Construction}, we will learn some general techniques for translating from one programming language to another. For compilers, we typically speak of a \emph{source language} and a \emph{target language}. A compiler is \emph{correct} if the meaning of programs is preserved through translation. \\

In the lectures for Compiler Construction, you will work with a compiler where the source language is a small, imperative language named SLANG. The target language will be the instruction set of a simple, stack-based machine, not unlike x86 or ARM. Translating from an imperative language to such a machine language is relatively easy, since the semantics of the machine are similar to those of the imperative language. \\

To give you a better understanding of how the techniques you are shown generalise to other languages, we will construct a compiler from a lazy, functional language to C for our supervisions. The translation process here will not be as easy since we will not only have to translate between paradigms, but also encode laziness in C. 
}
\end{center}

\section*{Exercises}

\begin{questions}
\question 
\begin{parts}
\part[2] What are the worst-case space and time complexities of Deterministic Finite Automata (DFAs)? 
\part[5] Words over an arbitrary alphabet $\Sigma$ (represented by the type variable $o$) can be defined in OCaml or Haskell as:
\begin{displaymath}
\begin{array}{c|c}
\textbf{OCaml} & \textbf{Haskell} \\ \hline
\begin{array}{lcl}
\mathbf{type}~{'o}~\mathit{word} & = & {'o}~\mathit{list}
\end{array} &
\begin{array}{lcl}
\mathbf{type}~\mathit{Word}~o & = & \hslist{o}
\end{array}
\end{array}
\end{displaymath}
You are also given the following definition of a type for DFAs:
\begin{displaymath}
\begin{array}{l|lcl}
\textbf{OCaml}   & \mathbf{type}~('q,{'o})~\mathit{dfa} & = & \mathit{DFA}~\mathbf{of}~('q \times {'o} \to {'q}) \times {'q} \times {'q}~\mathit{list} \\ \hline 
\textbf{Haskell} & \mathbf{data}~\mathit{DFA}~q~o       & = & \mathit{DFA}~((q,o) \to q)~q~\hslist{q}
\end{array}
\end{displaymath} 
The type parameters $q$ and $o$ represent states and symbols respectively. Therefore, a $\mathit{dfa}$ value consists of a transition function which, given a state and a symbol, returns a resulting state, an initial state, and a list of final states. Define a function:
\begin{displaymath}
\begin{array}{l|lcl}
\textbf{OCaml}   & \mathit{runDFA} & :  & ('q,{'o})~\mathit{dfa} \to {'o}~\mathit{word} \to \mathit{bool} \\ \hline 
\textbf{Haskell} & \mathit{runDFA} & :: & \mathit{DFA}~q~o \to \mathit{Word}~o \to \mathit{Bool}
\end{array}
\end{displaymath}
Given a DFA and a word, this function should return $\mathit{true}$ if the word is accepted by the DFA or $\mathit{false}$ otherwise. 
\part Non-deterministic Finite Automata (NFAs) can be converted into DFAs using \emph{Subset Construction} (\emph{e.g.} Section 3.4 of ``Machines and their Languages''\footnotemark[1]). We wish to implement
\begin{displaymath}
\begin{array}{l|lcl}
\textbf{OCaml}   & \mathit{runNFA} & :  & ('q,{'o})~\mathit{nfa} \to {'o}~\mathit{word} \to \mathit{bool} \\ \hline 
\textbf{Haskell} & \mathit{runNFA} & :: & \mathit{NFA}~q~o \to \mathit{Word}~o \to \mathit{Bool}
\end{array}
\end{displaymath}
which determines if a word is accepted by the NFA. Since NFAs can be converted into DFAs, we could implement this function using $\mathit{runDFA}$. 
\begin{subparts}
\subpart[2] Compare the computational complexity of simulating a NFA $N$ for a word $w$ with converting $N$ to a DFA $D$ and then simulating that for $w$.  
%\subpart Implement Subset Construction and $\mathit{runNFA}$ (this is very easy in Haskell FYI).
\end{subparts}
\part[2] A Computer Scientist who has not attended a course on Automata Theory or read Chapter 4 of ``Machines and their Languages''\footnote{\url{http://www.cl.cam.ac.uk/~mbg28/publications/g52mal-revision-guide.pdf}} has implemented a library for lexical analysis. The interface of the library is a single function:
\begin{displaymath}
\begin{array}{l|lcl}
\textbf{OCaml}   & \mathit{lexer} & : & (('o, {'t})~\mathit{rule})~\mathit{list} \to {'o}~\mathit{word} \to ('t~\mathit{list})~\mathit{option} \\ \hline 
\textbf{Haskell} & \mathit{lexer} & :: & \hslist{\mathit{Rule}~o~t} \to \mathit{Word}~o \to \mathit{Maybe}~\hslist{t}
\end{array}
\end{displaymath}
Given a list of rules and an input word, it returns either a list of tokens or $\mathit{None}$. Rules are defined as pairs of \textbf{regular} expressions and semantic actions:
\begin{displaymath}
\begin{array}{l|lcl}
\textbf{OCaml} & \mathbf{type}~('o, {'t})~\mathit{rule} & = & \mathit{Rule}~\mathbf{of}~{'o}~\mathit{RE} \times ({'o}~\mathit{word} \to {'t}) \\ \hline
\textbf{Haskell} & \mathbf{data}~\mathit{Rule}~o~t & = & \mathit{Rule}~(\mathit{RE}~o)~(\mathit{Word}~o \to t)
\end{array}
\end{displaymath}
The library uses the following algorithm:
\begin{enumerate}
\item Read a character from the input word and add it to a buffer
\item For every regular expression in the list of rules:
\begin{enumerate}
\item Apply the regular expression to the buffer
\item If successful:
\begin{enumerate}
\item Remember the rule that matched the input and go to Step 1
\end{enumerate}
\end{enumerate}
\item If no rule applied to the input word:
\begin{enumerate}
\item If a rule matched the input previously:
\begin{enumerate}
\item consume as much input as possible from the buffer while the rule still matched and apply the corresponding semantic action to the sub-word to generate a token
\item Proceed with Step 2
\end{enumerate} 
\item Else fail
\end{enumerate}
\end{enumerate}
Explain why this is computationally inefficient\footnote{Funnily enough, I may have a repository on GitHub which does exactly this: \url{https://github.com/mbg/Text.Lexer}}. 
\part[4] Suggest a better approach without changing the interface of the library. Justify your answer.   
%\part (Practical) Implement your own library for lexical analysis using the approach you have suggested.
\end{parts}
%\question (Discussion) In a language of your choice, and optionally with the help of a lexer generator of your choice, implement a lexer for the STG language.
%\question[3] Traditionally, a compiler reads a file, runs the contents through a lexer to obtain a list of tokens and then hands those to the parser which produces an abstract syntax tree. A \emph{threaded lexer} is a lexer which is called by the parser whenever it requires more tokens and only returns the next token, rather than a list of tokens. Explain why this is both more efficient (time and space) and leads to a better experience for programmers who use the compiler. \droppoints 
\question
\begin{parts}
\part[11] For each of the following words, decide whether they are members of $L(G)$ where the CFG $G$ is given by (lower-case characters are terminals and upper-case characters are non-terminals):
\begin{displaymath}
\begin{array}{lcl}
S & \to & cZ \mid X \mid Y \\
X & \to & aXb \mid \varepsilon \\
Y & \to & bbc \\
Z & \to & cZdd \mid \varepsilon
\end{array}
\end{displaymath}
If a word is in $L(G)$, you should give the full derivation for it.
\begin{subparts}
\subpart $\varepsilon \in L(G)$?
\subpart $a \in L(G)$?
\subpart $c \in L(G)$?
\subpart $ab \in L(G)$?
\subpart $ba \in L(G)$?
\subpart $bbc \in L(G)$?
\subpart $cd \in L(G)$?
\subpart $ccdd \in L(G)$?
\subpart $cabba \in L(G)$?
\subpart $cccddd \in L(G)$?
\subpart $aaabbb \in L(G)$?
\end{subparts}
\part[4] Explain the difference between leftmost and rightmost derivations of Context-Free Grammars. Give an example of \emph{one} parsing technique for each type of derivation. 
\part[2] Explain why some CFGs are ambiguous and illustrate your answer using as small of an example as you can think of.  
\part[5] You are given the following CFG for a simple, ambiguous expression language. Disambiguate it, assuming that $!$ binds more strongly than $+$ and $-$, which both bind equally strong. 
\begin{displaymath}
\begin{array}{lcl}
E & = & E + E \mid E - E \mid E! \mid (E) \mid a \mid b \mid c
\end{array}
\end{displaymath}  
We assume that $+$ and $-$ are left-associative.
\end{parts}
\question We will begin this question with some theory related to Context-Free Grammars which you may or may not have come across before. For illustration, we will use the following CFG as an example:
\begin{displaymath}
\begin{array}{lcl}
S & \to & aABe \\
A & \to & bcA \mid c \\
B & \to & d
\end{array}
\end{displaymath}
Now we can define the following terminology:
\begin{parts}
\part[1] An \emph{item} is a production with a dot anywhere in the right-hand side. \emph{E.g.}
\begin{displaymath}
\begin{array}{cc}
B \to \cdot d & B \to d \cdot
\end{array}
\end{displaymath}
are items for $B$. An item is \emph{complete} if the dot is the rightmost symbol in the item, so that \emph{e.g.} $B \to d \cdot$ is complete. Give all items for $S$ and state whether they are complete or not.  
\part[3] Given an arbitrary CFG $G = \langle N, T, P, S \rangle$, a word $\phi \in (N \cup T)^*$ is a \emph{sentential form} for $G$ if and only if $S \overset{*}{\underset{G}{\Rightarrow}} \phi$. A \emph{right-sentential form} is a sentential form that can be derived by rightmost derivation. Finally, a \emph{handle} of a right-sentential form $\phi$ is a substring $\alpha$ of $\phi$ such that $S \overset{*}{\underset{\mathit{rm}}{\Rightarrow}} \delta Aw \underset{\mathit{rm}}{\Rightarrow} \delta \alpha w$ and $\delta \alpha w = \phi$ for some $A \in N$, where $\alpha, \delta, \phi \in (N \cup T)^*$ and $w \in T^*$. For an unambiguous grammar, the rightmost derivation is unique and we can therefore talk about ``the handle'' as opposed to merely ``a handle''. The following is a rightmost derivation for our grammar:
\begin{displaymath}
S \underset{\mathit{rm}}{\Rightarrow} aABe \underset{\mathit{rm}}{\Rightarrow} aAde \underset{\mathit{rm}}{\Rightarrow} abcAde
\end{displaymath}
Here $aABe$, $aAde$, and $abcAde$ are right-sentential forms. What is the handle for each?  
\part[3] A \emph{viable prefix} of a right-sentential form $\phi$ is any prefix $\gamma$ of $\phi$ ending no farther right than the right end of the handle of $\phi$. An item $A \to \alpha \cdot \beta$ is \emph{valid} for a viable prefix $\gamma$ is there is a rightmost derivation
\begin{displaymath}
S \overset{*}{\underset{\mathit{rm}}{\Rightarrow}} \delta Aw \underset{\mathit{rm}}{\Rightarrow} \delta \alpha \beta w
\end{displaymath}
and $\delta \alpha = \gamma$. List all viable prefixes for each of the sentential forms you were given in the previous part ($aABe$, $aAde$, and $abcAde$).  
\part[3] For each non-$\varepsilon$ viable prefix you gave in your answer for the previous part, give the corresponding valid item.  
\part[6] For every CFG, the set of viable prefixes is regular. Therefore, we can construct a DFA which recognises viable prefixes and their valid items. The states of such a DFA are sets of items valid for a recognised viable prefix. Construct a DFA which recognises viable prefixes for the CFG given at the start of this question. By convention, when drawing such DFAs, we do not include error states and transitions to them. 
\part[10] Knowing the valid item(s) for a viable prefix allows a rightmost derivation in reverse to be found:
\begin{itemize}
\item If $A \to \alpha \cdot$ is a complete, valid item for a viable prefix $\gamma = \delta \alpha$ of a right-sentential form $\gamma w$ ($w \in T^*$), then it \emph{appears} that $A \to \alpha$ can be used at the last step, and that the previous right-sentential form is $\delta A w$.
\item If this is indeed always the case for an arbitrary CFG $G$, then for any $x \in L(G)$, since $x$ is a right-sentential form, previous right-sentential forms can be determined until the start symbol is reached, giving a right-most derivation of $x$.
\end{itemize}
CFGs for which knowing a complete valid item is sufficient to determine the previous right-sentential form are called $LR(0)$. Given a DFA which recognises viable prefixes, a LR(0) parser can be constructed as follows:
\begin{itemize}
\item In a state without complete items: read next terminal symbol and push it onto a stack and move to a new state by following the transition corresponding to the read symbol (Shift).
\item In a state with a single complete item, the top of the stack will contain the handle of the current right-sentential form. This handle is just the right-hand side of the valid item. Reduce to the previous right-sentential form by replacing the handle on the stack with the left-hand side of the valid item. Finally, move to the state indicated by the new viable prefix on the parse stack (Reduce).
\item If a state contains both complete and incomplete items, or if a state contains more than one complete item, then the grammar is not LR(0).
\end{itemize} 
Using the DFA you produced as answer for the previous part, show how to parse $abccde$ starting from an empty stack.  
\part[4] Consider the words $abcbcbccde$ and $abcbcbcbcbccde$. What happens to the parse stack when you parse them? Suggest why this may be happening and how you may be able to improve it.  
\part[4] In general, if $A \to \alpha \cdot$ is a complete, valid item for a viable prefix $\gamma = \delta \alpha$, we only know that it \emph{may} be possible to use $A \to \alpha$ to derive $\gamma w$ from $\delta A w$. 
\begin{itemize}
\item $A \to \alpha \cdot$ may be valid because of a different rightmost derivation $S \overset{*}{\underset{\mathit{rm}}{\Rightarrow}} \delta Aw' \underset{\mathit{rm}}{\Rightarrow} \phi w'$.
\item There could be two or more complete items valid for $\gamma$.
\item There could be a handle of $\gamma w$ that includes symbols of $w$.
\end{itemize}
Explain how lookahead addresses this problem.  
\part[2] Explain what problem LALR parsers address and how they can be obtained from LR parsers.  
\end{parts}

\end{questions}

\section*{Practical Exercises}

For the practical exercises, we will implement a compiler from the STG language (shown in \autoref{fig:stglang}) to C. You may use a programming language of your choice, but note that skeleton code is available in Haskell (and will save you much of the work). 

\begin{mdframed}
\textbf{Skeleton Code}\\
You can obtain a copy of the skeleton code by cloning the following repository on GitHub (you may wish to create a fork on your own account instead of cloning it directly if you wish to submit a link to your repository as your answer):
\begin{verbatim}
$ git clone https://github.com/mbg/compconstr-code
\end{verbatim}
If you have not used Haskell before, download and install the latest version of the Haskell Platform from \url{https://www.haskell.org/platform/}. Once installed, navigate to the directory containing the skeleton code, set up a Cabal sandbox, and install the dependencies:
\begin{verbatim}
$ cd compconstr-code
$ cabal sandbox init
$ cabal install --only-dependencies
$ cabal configure
\end{verbatim}
Once all dependencies have been installed, verify that the program compiles successfully (repeat this step whenever you wish to re-compile the compiler):
\begin{verbatim}
$ cabal build
\end{verbatim}
If successful, this should create an executable in the \texttt{./dist/build/stg/} directory. You can invoke the compiler with \emph{e.g.}, although note that this will fail with a parse error until you have completed the exercises below:
\begin{verbatim}
$ ./dist/build/stg/stg ./tests/Map.stg
\end{verbatim} 
The compiler will attempt to parse all files specified as inputs to the program. If a file can be parsed, the generated abstract syntax tree will be pretty-printed to the standard output. If an error occurs, that error will be displayed instead (which is what happens in this case). It may help you to look at the \texttt{Map.stg} file and the parse error that occurs to figure out what you need to do for the exercises below.
\end{mdframed}

\begin{questions}
%\question Abstract machines, typically have an instruction set over which the operational semantics are defined. Programs are sequences of instructions. In our case, the instruction set consists of only $\mathbf{PUSH}$ and $\mathbf{ADD}$. However, as we have noted above, compiling a functional language to such an instruction set is not straight-forward.

%The Spineless Tagless G-Machine\footnote{A full description of this machine may be found in \url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.3729&rep=rep1&type=pdf} which you may find useful. Only Part II is relevant to this exercise.} was designed as a target machine for non-strict, functional languages (primarily Haskell). Programs for the STG machine are written in the STG language which, unlike most other machine languages, is a functional language which is given an operational semantics. This makes it easy to translate more high-level functional languages into STG programs. Its syntax is shown in \autoref{fig:stglang}. We use a dark purple, italic font ($\mathit{symbol}$) to denote non-terminals, a light purple, typewriter font ($\terminal{terminal}$) to denote terminals, and a regular black font for everything else. Sequences are denoted using $\ldots$ and numbered symbols.

\question Identify the terminal symbols in the context-free grammar for the concrete syntax of the STG language (\autoref{fig:stglang}). The first stage of a compiler typically reads source files (plain text) and converts them into lists of lexical tokens. Tokens typically correspond to the terminal symbols in the context-free grammar of a language. In a programming language of your choice, implement a representation of lexical tokens for the STG language. If you are using the skeleton code, a corresponding type has already been defined in \texttt{src/Token.hs}. However, one or more token types have been omitted -- add them as new data constructors to the $\mathit{Token}$ type. You will also have to extend the definition of the $\mathit{pp}$ function at the bottom of the file with corresponding cases for the token types you have added.

\question Construct a lexer which reads a source file and converts it into a list of tokens. If you are using the skeleton code, the lexer is specified in the \texttt{src/Lexer.x} file. We are using a lexer generator named \emph{Alex} for this purpose\footnote{You can find the documentation for Alex at \url{https://www.haskell.org/alex/doc/html/}}. The specification largely consists of regular expressions and semantic actions (in Haskell) which are invoked when a regular expression matches the input. For example,
\begin{verbatim}
"letrec"                    { makeToken TLetRec                         }
\end{verbatim}
tries to exactly match the string \texttt{letrec} and constructs a $\mathit{TLetRec}$ token if successful. You should add rules for the token types you added for the previous question.
\question \autoref{fig:stglang} shows the context-free grammar for the concrete syntax of the STG language. Design a corresponding grammar for the abstract syntax of the language and implement it in a language of your choice. If you are using the skeleton code, you may find the code in \texttt{src/AST.hs}. There are some data type constructors missing, however, and you will need to add them. Don't forget to also add corresponding cases to the definitions of the $\mathit{pp}$ function at the bottom of the file.

\question In a language of your choice, implement a parser for the STG language. The parser should take a list of tokens as input and produce an abstract syntax tree if possible or an error if not. If you're using the skeleton code, the parser is specified in \texttt{src/Parser.y}. Here we are using a parser generator named \emph{Happy}\footnote{You can find the documentation for Happy at \url{https://www.haskell.org/happy/doc/html/}}. The specification consists of non-terminal symbols, productions, and semantic actions. For example,
\begin{verbatim}
default :: { DefaultAlt }
default : VAR '->' expr              {% mkDefaultVar $1 $3                  }
        | DEFAULT '->' expr          {% mkDefault $1 $3                     }
\end{verbatim}
defines a non-terminal named \texttt{default} whose semantic actions return a value of type $\mathit{DefaultAlt}$. The non-terminal has two productions and corresponding semantic actions -- note that the functions used in the semantic actions are defined in \texttt{src/P.hs}. The productions make use of another non-terminal, \texttt{expr}, which is defined elsewhere in \texttt{src/Parser.y}, and two terminals. All terminals are declared at the top of the file. For example,
\begin{verbatim}
DEFAULT                          { (TDefault, $$)                       }
\end{verbatim}
maps the \texttt{DEFAULT} terminal to a token identified by $\mathit{TDefault}$ and gives it its position in the source file as value (the \texttt{\$\$} part). Add productions for the constructors you added for the previous question, as well as terminals for the token types you added for the first practical question. For the semantic actions, corresponding function stubs exist in \texttt{src/P.hs} -- complete them by replacing $\mathit{undefined}$.

\question Thoroughly test your parser to ensure that all valid programs in the STG language, according to the grammar in \autoref{fig:stglang}, can be parsed successfully. Explain how you have tested your parser and why you are convinced that it is correct.
\end{questions}

\newpage
\section*{Appendix}

\begin{figure}[h]
\begin{mdframed}
    \begin{displaymath}
    \begin{array}{llcll}
    \multicolumn{5}{c}{\begin{array}{cc}
    \mathit{var} \in \texttt{[a-z][a-zA-Z0-9]*} & \mathit{ctr} \in \texttt{[A-Z][a-zA-Z0-9]*}
    \end{array}}\\\\
    \text{\bl{Program}} & \mathit{prog} & \bl{\to} & \mathit{binds} \\
    \text{\bl{Bindings}} & \mathit{binds} & \bl{\to} & \mathit{var}_1 \terminal{ = } \mathit{lf}_1\terminal{;} \ldots \terminal{;} \mathit{var}_n \terminal{ = } \mathit{lf}_n\terminal{;} & \bl{n \ge 1}\\
    \text{\bl{$\lambda$-forms}} & \mathit{lf} & \bl{\to} & \mathit{vars}_f~\terminal{\textbackslash} \pi~\mathit{vars}_a \terminal{ -> } \mathit{expr} \\
    \text{\bl{Update flag}} & \pi & \bl{\to} & \terminal{u} & \text{\bl{Updatable}} \\
    &     & \bl{\mid}     & \terminal{n} & \text{\bl{Not updatable}} \\
    \text{\bl{Expression}} & \mathit{expr} & \bl{\to}  & \terminal{let}~\mathit{binds}~\terminal{in}~\mathit{expr} & \text{\bl{Local definition}} \\
    &               & \bl{\mid} & \terminal{letrec}~\mathit{binds}~\terminal{in}~\mathit{expr} & \text{\bl{Local recursion}} \\
    &               & \bl{\mid} & \terminal{case}~\mathit{expr}~\terminal{of}~\mathit{alts} & \text{\bl{Case expression}} \\
    &               & \bl{\mid} & \mathit{var}~\mathit{atoms} & \text{\bl{Application}} \\
    &               & \bl{\mid} & \mathit{constr}~\mathit{atoms} & \text{\bl{Saturated constructor}} \\
    &               & \bl{\mid} & \mathit{prim}~\mathit{atoms} & \text{\bl{Saturated built-in operator}} \\
    &               & \bl{\mid} & \mathit{literal}  \\
    \text{\bl{Alternatives}} & \mathit{alts} & \bl{\to}  & \mathit{aalt}_1 \terminal{;} \ldots \terminal{;} \mathit{aalt}_n \terminal{;} \mathit{default} & \bl{n \ge 0} \text{ \bl{(Algebraic)}} \\
    &               & \bl{\mid} & \mathit{palt}_1 \terminal{;} \ldots \terminal{;} \mathit{palt}_n \terminal{;} \mathit{default} & \bl{n \ge 0} \text{ \bl{(Primitive)}} \\
    \text{\bl{Algebraic alt}} & \mathit{aalt} & \bl{\to}  & \mathit{constr}~\mathit{vars}~\terminal{->}~\mathit{expr} \\
    \text{\bl{Primitive alt}} & \mathit{palt} & \bl{\to}  & \mathit{literal}~\terminal{->}~\mathit{expr} \\
    \text{\bl{Default alt}} & \mathit{default} & \bl{\to}  & \mathit{var}~\terminal{->}~\mathit{expr} \\
    &                  & \bl{\mid} & \terminal{default ->}~\mathit{expr}\\
    \text{\bl{Literals}} & \mathit{literal} & \bl{\to}  & \terminal{0\#}~\bl{\mid}~\terminal{1\#}~\bl{\mid}~\ldots & \text{\bl{Primitive integers}}\\
    \text{\bl{Primitive ops}} & \mathit{prim} & \bl{\to}  & \terminal{+\#}~\bl{\mid}~\terminal{-\#}~\bl{\mid}~\terminal{*\#}~\bl{\mid}~\terminal{/\#}  & \text{\bl{Primitive integer ops}}\\     
    \text{\bl{Variable lists}} & \mathit{vars} & \bl{\to} & \terminal{\{}~\mathit{var}_1~\terminal{,} \ldots \terminal{,}~\mathit{var}_n~\terminal{\}} & \bl{n \ge 0}\\  
    \text{\bl{Atom lists}} & \mathit{atoms} & \bl{\to} & \terminal{\{}~\mathit{atom}_1~\terminal{,} \ldots \terminal{,}~\mathit{atom}_n~\terminal{\}} & \bl{n \ge 0}\\ 
    \text{\bl{Atoms}} & \mathit{atom}  & \bl{\to} & \mathit{var} ~\bl{\mid}~ \mathit{literal}            \\                        
    \end{array}
    \end{displaymath}
    \caption{STG language}
    \label{fig:stglang}
\end{mdframed}
\end{figure}

\end{document}
